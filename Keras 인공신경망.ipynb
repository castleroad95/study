{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성 방법\n",
    "\n",
    "## tf.keras.layers.Dense\n",
    " \n",
    "### dense layer\n",
    " : 완전 연결 계층으로 Input과 Output을 모두 연결해준다. (밀집층을 구현)\n",
    " \n",
    " 1. 함수형태\n",
    " \n",
    " tf.keras.layers.Dense(\n",
    "    units, activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None,\n",
    "    activity_regularizer=None, kernel_constraint=None, bias_constraint=None,\n",
    "    **kwargs\n",
    "    )\n",
    "    \n",
    "  \n",
    "   unit : 출력 공간의 차원\n",
    "  \n",
    "   activation : 활성화 함수\n",
    "  \n",
    "   kernel_initializer : 가중치 행렬\n",
    "  \n",
    "  \n",
    " 2. 활성화 함수 종류\n",
    " \n",
    " - step function : 임계 값을 기준으로 1 또는 0(활성화 혹은 비활성화)\n",
    " - sign function : 임계 값을 기준으로 +1 또는 -1 출력\n",
    " - sigmoid function : 모든 점에서 음이 아닌 미분 값을 가지고 단하나의 변곡점을 가지는 함수, 기울기 소실의 원인\n",
    " - tanh fuction : sigmoid의 문제점 해결\n",
    " - ReLU : x<0 y=0, x값이 0보다 큰 경우 y 값도 증가, sigmoid 기울기 소실 문제 해결, x<0인 경우 기울기가 0 이기 때문에 뉴런이 죽을 수 있음\n",
    " - Leaky ReLU : ReLU의 문제점인 뉴런이 죽는 현상을 해결\n",
    " - Softmax :  출력값이 여러개가 주어지고 목표가 다범주인 경우 각 범주에 속할 확률 제공, 출력값의 총합은 1\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras\n",
    "\n",
    "### 1. sequential 모델\n",
    " : 각 레이어에 정확히 하나의 입력tensor와 하나의 출력 tensor가 있는 일반 layer 스택에 적합하다.\n",
    " \n",
    " 적합하지 않은 경우\n",
    " \n",
    " - 모델에 다중입력 또는 다중 출력이 있다.\n",
    " - 레이어에 다중 입력 또는 다중 출력이 있다.\n",
    " - 레이어 공유를 해야한다.\n",
    " - 비선형 토폴로지를 원한다.(ex: 잔류 연결, 다중 분기 모델)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "\n",
    "\n",
    "\n",
    "# 1. sequential 모형 생성\n",
    "model= tf.keras.models.Sequential()\n",
    "\n",
    "# 2. sequential model에 add를 하여 초기 모형 추가\n",
    "model.add(Dense(10,input_shape(1000,),activation='relu'))\n",
    "\n",
    "# 3. 모델에 add하여 dense, dropout, flaten 등 층 추가\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "\n",
    "# 4. 모형 학습/훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 5. history 저장\n",
    "history = model.fit(x_train.toarray(), y_train,\n",
    "                    epochs=30, callbacks=[tf.keras.callbacks.EarlyStopping()],\n",
    "                    validation_split=.3, verbose=0)\n",
    "\n",
    "# 6. 모형 손실과 정확도 그래프\n",
    "\n",
    "# loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train_loss', 'val_loss'])\n",
    "plt.title('LOSS')\n",
    "plt.show()\n",
    "\n",
    "# accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train_accuracy', 'val_accuracy'])\n",
    "plt.title('ACCURACY')\n",
    "plt.show()\n",
    "\n",
    "# 7. 모형 평가\n",
    "model.evaluate(x_test.toarray(), y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
